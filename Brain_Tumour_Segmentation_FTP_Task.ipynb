{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVi9WuT7wZeD"
      },
      "source": [
        "## Brain Tumor Segmentation -> Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q_o2UDpwZeE"
      },
      "outputs": [],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "!pip install -q pytorch-lightning==1.5.10\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUMd6DgiwZeG"
      },
      "source": [
        "## Setup imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "cg5HfmYMwZeG"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning\n",
        "from monai.utils import set_determinism\n",
        "from monai.transforms import (\n",
        "    AsDiscrete,\n",
        "    EnsureChannelFirstd,\n",
        "    Compose,\n",
        "    CropForegroundd,\n",
        "    LoadImaged,\n",
        "    Orientationd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    ScaleIntensityRanged,\n",
        "    Spacingd,\n",
        "    EnsureType,\n",
        "    MapTransform,\n",
        "    Activations,\n",
        "    Activationsd,\n",
        "    AsDiscreted,\n",
        "    Invertd,\n",
        "    NormalizeIntensityd,\n",
        "    RandFlipd,\n",
        "    RandScaleIntensityd,\n",
        "    RandShiftIntensityd,\n",
        "    RandSpatialCropd,\n",
        "    EnsureTyped,\n",
        ")\n",
        "from monai.networks.nets import UNet\n",
        "from monai.networks.layers import Norm\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceLoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.data import CacheDataset, list_data_collate, decollate_batch, DataLoader\n",
        "from monai.config import print_config\n",
        "from monai.apps import download_and_extract,DecathlonDataset\n",
        "from monai.handlers.utils import from_engine\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "\n",
        "print_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h1ClFcLwZeJ"
      },
      "source": [
        "## Setup data directory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "E8kVsKdbwZeJ"
      },
      "outputs": [],
      "source": [
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "print(root_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICMSBwnXwZeK"
      },
      "source": [
        "## Download dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "DbJsJNdEwZeK"
      },
      "outputs": [],
      "source": [
        "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task01_BrainTumour.tar\"\n",
        "md5 = \"240a19d752f0d9e9101544901065d872\"\n",
        "\n",
        "compressed_file = os.path.join(root_dir, \"Task01_BrainTumour.tar\")\n",
        "data_dir = os.path.join(root_dir, \"Task01_BrainTumour\")\n",
        "if not os.path.exists(data_dir):\n",
        "    download_and_extract(resource, compressed_file, root_dir, md5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
        "    \"\"\"\n",
        "    Convert labels to multi channels based on brats classes:\n",
        "    label 1 is the peritumoral edema\n",
        "    label 2 is the GD-enhancing tumor\n",
        "    label 3 is the necrotic and non-enhancing tumor core\n",
        "    The possible classes are TC (Tumor core), WT (Whole tumor)\n",
        "    and ET (Enhancing tumor).\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, data):\n",
        "        d = dict(data)\n",
        "        for key in self.keys:\n",
        "            result = []\n",
        "            # merge label 2 and label 3 to construct TC\n",
        "            result.append(torch.logical_or(d[key] == 2, d[key] == 3))\n",
        "            # merge labels 1, 2 and 3 to construct WT\n",
        "            result.append(torch.logical_or(torch.logical_or(d[key] == 2, d[key] == 3), d[key] == 1))\n",
        "            # label 2 is ET\n",
        "            result.append(d[key] == 2)\n",
        "            d[key] = torch.stack(result, axis=0).float()\n",
        "        return d"
      ],
      "metadata": {
        "id": "YXafYODW00SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5yLqPIdwZeL"
      },
      "source": [
        "## Define the LightningModule\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDY2GTGTwZeL"
      },
      "outputs": [],
      "source": [
        "class Net(pytorch_lightning.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self._model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=4,\n",
        "            out_channels=3,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.BATCH,\n",
        "        )\n",
        "        self.loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
        "        self.post_pred = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(argmax=True, to_onehot=3)])\n",
        "        self.post_label = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(to_onehot=3)])\n",
        "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
        "        self.best_val_dice = 0\n",
        "        self.best_val_epoch = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._model(x)\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # set up the correct data path\n",
        "        train_images = sorted(glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
        "        train_labels = sorted(glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
        "        data_dicts = [\n",
        "            {\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)\n",
        "        ]\n",
        "        train_files, val_files = data_dicts[:-9], data_dicts[-9:]\n",
        "\n",
        "        # set deterministic training for reproducibility\n",
        "        set_determinism(seed=0)\n",
        "\n",
        "        # define the data transforms\n",
        "        train_transform = Compose(\n",
        "    [\n",
        "        # load 4 Nifti images and stack them together\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=\"image\"),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        Spacingd(\n",
        "            keys=[\"image\", \"label\"],\n",
        "            pixdim=(1.0, 1.0, 1.0),\n",
        "            mode=(\"bilinear\", \"nearest\"),\n",
        "        ),\n",
        "        RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[224, 224, 144], random_size=False),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
        "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
        "        RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
        "        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
        "    ]\n",
        ")\n",
        "        val_transform = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=\"image\"),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        Spacingd(\n",
        "            keys=[\"image\", \"label\"],\n",
        "            pixdim=(1.0, 1.0, 1.0),\n",
        "            mode=(\"bilinear\", \"nearest\"),\n",
        "        ),\n",
        "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
        "    ]\n",
        ")\n",
        "        # we use cached datasets - these are 10x faster than regular datasets\n",
        "        self.train_ds = CacheDataset(\n",
        "            data=train_files,\n",
        "            transform= train_transform,\n",
        "            cache_rate=1.0,\n",
        "            num_workers=4,\n",
        "        )\n",
        "        self.val_ds = CacheDataset(\n",
        "            data=val_files,\n",
        "            transform= val_transform,\n",
        "            cache_rate=1.0,\n",
        "            num_workers=4,\n",
        "        )\n",
        "\n",
        "    #         self.train_ds = monai.data.Dataset(\n",
        "    #             data=train_files, transform=train_transforms)\n",
        "    #         self.val_ds = monai.data.Dataset(\n",
        "    #             data=val_files, transform=val_transforms)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_loader = DataLoader(\n",
        "            self.train_ds,\n",
        "            batch_size=1,\n",
        "            shuffle=True,\n",
        "            num_workers=4,\n",
        "            collate_fn=list_data_collate,\n",
        "        )\n",
        "        return train_loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        val_loader = DataLoader(self.val_ds, batch_size=1, num_workers=4)\n",
        "        return val_loader\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self._model.parameters(), 1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, labels = batch[\"image\"], batch[\"label\"]\n",
        "        output = self.forward(images)\n",
        "        loss = self.loss_function(output, labels)\n",
        "        tensorboard_logs = {\"train_loss\": loss.item()}\n",
        "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, labels = batch[\"image\"], batch[\"label\"]\n",
        "        roi_size = (240, 240, 160)\n",
        "        sw_batch_size = 1\n",
        "        outputs = sliding_window_inference(images, roi_size, sw_batch_size, self.forward)\n",
        "        loss = self.loss_function(outputs, labels)\n",
        "        outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
        "        labels = [self.post_label(i) for i in decollate_batch(labels)]\n",
        "        self.dice_metric(y_pred=outputs, y=labels)\n",
        "        return {\"val_loss\": loss, \"val_number\": len(outputs)}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        val_loss, num_items = 0, 0\n",
        "        for output in outputs:\n",
        "            val_loss += output[\"val_loss\"].sum().item()\n",
        "            num_items += output[\"val_number\"]\n",
        "        mean_val_dice = self.dice_metric.aggregate().item()\n",
        "        self.dice_metric.reset()\n",
        "        mean_val_loss = torch.tensor(val_loss / num_items)\n",
        "        tensorboard_logs = {\n",
        "            \"val_dice\": mean_val_dice,\n",
        "            \"val_loss\": mean_val_loss,\n",
        "        }\n",
        "        if mean_val_dice > self.best_val_dice:\n",
        "            self.best_val_dice = mean_val_dice\n",
        "            self.best_val_epoch = self.current_epoch\n",
        "        print(\n",
        "            f\"current epoch: {self.current_epoch} \"\n",
        "            f\"current mean dice: {mean_val_dice:.4f}\"\n",
        "            f\"\\nbest mean dice: {self.best_val_dice:.4f} \"\n",
        "            f\"at epoch: {self.best_val_epoch}\"\n",
        "        )\n",
        "        return {\"log\": tensorboard_logs}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = Net().prepare_data()\n",
        "val_data_example = a.val_ds[4]\n",
        "print(f\"image shape: {val_data_example['image'].shape}\")\n",
        "plt.figure(\"image\", (24, 6))\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 4, i + 1)\n",
        "    plt.title(f\"image channel {i}\")\n",
        "    plt.imshow(val_data_example[\"image\"][i, :, :, 60].detach().cpu(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MezzS9deHbYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qCA85MbwZeM"
      },
      "source": [
        "## Run the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "tags": [],
        "id": "YJtcostKwZeN"
      },
      "outputs": [],
      "source": [
        "# initialise the LightningModule\n",
        "net = Net()\n",
        "\n",
        "# set up loggers and checkpoints\n",
        "log_dir = os.path.join(root_dir, \"logs\")\n",
        "tb_logger = pytorch_lightning.loggers.TensorBoardLogger(save_dir=log_dir)\n",
        "\n",
        "# initialise Lightning's trainer.\n",
        "trainer = pytorch_lightning.Trainer(\n",
        "    gpus=[0],\n",
        "    max_epochs=2,\n",
        "    logger=tb_logger,\n",
        "    enable_checkpointing=True,\n",
        "    num_sanity_val_steps=1,\n",
        "    log_every_n_steps=16,\n",
        ")\n",
        "\n",
        "# train\n",
        "trainer.fit(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "GTdcaJRiwZeO"
      },
      "outputs": [],
      "source": [
        "print(f\"train completed, best_metric: {net.best_val_dice:.4f} \" f\"at epoch {net.best_val_epoch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe3ziXqnwZeP"
      },
      "source": [
        "## View training in tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_UezYaEwZeP"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=$log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ANer2-AwZeQ"
      },
      "source": [
        "## Check best model output with the input image and label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "lines_to_next_cell": 2,
        "scrolled": false,
        "id": "HNGjAaXAwZeQ"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "device = torch.device(\"cuda:0\")\n",
        "net.to(device)\n",
        "with torch.no_grad():\n",
        "    for i, val_data in enumerate(net.val_dataloader()):\n",
        "        roi_size = (240, 160, 160)\n",
        "        sw_batch_size = 4\n",
        "        val_outputs = sliding_window_inference(val_data[\"image\"].to(device), roi_size, sw_batch_size, net)\n",
        "        # plot the slice [:, :, 80]\n",
        "        plt.figure(\"check\", (18, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(f\"image {i}\")\n",
        "        plt.imshow(val_data[\"image\"][0, 0, :, :, 80], cmap=\"gray\")\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(f\"label {i}\")\n",
        "        plt.imshow(val_data[\"label\"][0, 0, :, :, 80])\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(f\"output {i}\")\n",
        "        plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, :, 80])\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx5zKrLfwZeR"
      },
      "source": [
        "## Cleanup data directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUpakiB2wZeR"
      },
      "outputs": [],
      "source": [
        "if directory is None:\n",
        "    shutil.rmtree(root_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}